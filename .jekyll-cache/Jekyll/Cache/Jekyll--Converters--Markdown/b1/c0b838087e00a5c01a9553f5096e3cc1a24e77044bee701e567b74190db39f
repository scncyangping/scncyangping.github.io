I"<h3 id="hadoop初识">Hadoop初识</h3>

<ul>
  <li>
    <p>狭义的Hadoop: 是一个舍和大数据分布式存储(HDFS)、分布式计算(MapReduce)和资源调度(YARN)的平台</p>
  </li>
  <li>
    <p>广义Hadoop: 指的是Hadoop的生态系统,包含各种只解决某一个特定问题域的子系统，zk、hiv(sql查询)、pig(脚本)、R语言、Hbase、sqoop(将关系型数据库与hadoop的数据进行交换)、Flume(日志收集框架)</p>
  </li>
</ul>

<h4 id="基础">基础</h4>

<ul>
  <li>定义
    <ol>
      <li>提供分布式的存储(一个文件被拆分成很多歌快,并且以副本的方式存储在各个节点中)和计算</li>
      <li>是一个分布式的系统基础架构: 用户可以在不了解分布式底层细节的情况下进行使用</li>
    </ol>
  </li>
  <li>核心模块
    <ol>
      <li>Hadoop Common</li>
      <li>Hadoop Distributed File System 【(HDFS) 分布式文件系统,将文件分布式存储在很多的服务器上】</li>
      <li>Hadoop YARN(作业调度资源管理)</li>
      <li>Haddop MapReduce(分布式计算框架,在很多机器上分布式并行计算)</li>
    </ol>
  </li>
</ul>

<h4 id="hdfs">HDFS</h4>

<ul>
  <li>源自Google的GFS论文</li>
  <li>HDFS是GFS的克隆版</li>
  <li>HDFS的特点(扩展性、容错性、海量数据存储)</li>
</ul>

<h5 id="特性">特性</h5>

<ol>
  <li>将文件切分成指定大小的数据快,并以多副本的方式存储在多个机器上
    <ol>
      <li>块(block): 默认的blocksize是128M</li>
      <li>副本: 默认3个副本</li>
    </ol>
  </li>
  <li>数据切分,多副本容错,操作对用户透明</li>
</ol>

<h4 id="mapreduce">MapReduce</h4>

<ul>
  <li>源自Google的MapReduce论文</li>
  <li>MapReduce是Google MapReduce的克隆版</li>
  <li>MapReduce特点: 扩展性、容错性、海量数据离线处理</li>
</ul>

<h4 id="yarn">YARN</h4>

<ul>
  <li>YARN : Yet Another Resource Negotiiator</li>
  <li>负责整个集群资源的管理和调度</li>
  <li>YARN特点: 扩展性、容错性、多框架资源统一调度</li>
</ul>

<h4 id="优势">优势</h4>

<ul>
  <li>高可靠性
    <ol>
      <li>数据存储: 数据多副本</li>
      <li>运行可靠</li>
    </ol>
  </li>
  <li>搞扩展性
    <ol>
      <li>存储/计算资源不够时,可以横向的线性扩展机器</li>
      <li>一个集群中可以包含数以千计的节点</li>
    </ol>
  </li>
  <li>成熟的生态圈</li>
</ul>

<h4 id="发行版本选择">发行版本选择</h4>
<ul>
  <li>Apache
    <ol>
      <li>纯开源</li>
      <li>不同版本、不同框架整合不方便</li>
    </ol>
  </li>
  <li>CDH: https://www.cloudera.com
    <ol>
      <li>cm (cloudera manager) 通过页面一键安装各种框架,方便升级,支持impala</li>
      <li>cm不开源,与社区版本有些出入</li>
    </ol>
  </li>
  <li>Hortonworks: HDP
    <ol>
      <li>纯开源,支持tez,企业发布自己的数据平台可以直接基于页面框架改造</li>
      <li>企业级安全不开源</li>
    </ol>
  </li>
  <li>MapR</li>
</ul>

<h4 id="使用cdh安装">使用CDH安装</h4>

<ul>
  <li>CDH 相关软件包下载地址
    <blockquote>
      <p>http://archive.cloudera.com/cdh5/cdh/5/</p>
    </blockquote>
  </li>
  <li>使用版本：hadoop-2.6.0-cdh5.15.1</li>
  <li>Hadoop 下载</li>
  <li>JDK 下载</li>
  <li>hive 下载</li>
</ul>

<h4 id="安装">安装</h4>

<h5 id="jdk-安装">JDK 安装</h5>

<ol>
  <li>拷贝JDK到虚拟机
    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>scp jdk-8u201-linux-x64.tar.gz  hadoop@172.16.114.132:~/software/
</code></pre></div>    </div>
  </li>
  <li>解压到～/app/ 目录
    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tar -zxvf jdk-8u201-linux-x64.tar.gz  -C ~/app/
</code></pre></div>    </div>
  </li>
  <li>配置无密码登陆
    <ol>
      <li>ssh-keygen -t rsa</li>
      <li>cat id_rsa.pub » authorized_keys</li>
      <li>chmod 600 authorized_keys</li>
    </ol>
  </li>
</ol>

<h5 id="hadoop安装">Hadoop安装</h5>
<ul>
  <li>下载安装包拷贝到虚拟机</li>
  <li>解压到对应目录</li>
  <li>目录结构
    <ol>
      <li>bin : hadoop客户端命令</li>
      <li>etc/hadoop : 相关配置文件目录</li>
      <li>sbin : 启动hadoop相关进程的脚本</li>
      <li>lib : 依赖包</li>
      <li>share : 常用例子</li>
    </ol>
  </li>
</ul>

<h5 id="基础配置">基础配置</h5>

<ul>
  <li>/etc/hadoop/hadoop-env.sh （配置JAVA_HOME）</li>
  <li>/etc/hadoop/core-site.xml  （配置文件系统主节点)</li>
</ul>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;property&gt;
    &lt;name&gt;fs.defaultFS&lt;/name&gt;
    &lt;value&gt;hdfs://hadoop000:8020&lt;/value&gt;
&lt;/property&gt;
</code></pre></div></div>
<ul>
  <li>/etc/hadoop/hdfs-site.xml (配置文件副本系数)</li>
</ul>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;property&gt;
    &lt;name&gt;dfs.replication&lt;/name&gt;
    &lt;value&gt;1&lt;/value&gt;
&lt;/property&gt;

默认文件存储目录在 /tmp/目录下,这个目录在重启的时候会清空
所以重新指定一下目录
&lt;property&gt;
    &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;
    &lt;value&gt;/home/hadoop/app/tmp&lt;/value&gt;
&lt;/property&gt;
</code></pre></div></div>

<ul>
  <li>slaves (单机的时候修改 localhost为hadoop000(自己设置的))</li>
</ul>

<h5 id="启动">启动</h5>

<ul>
  <li>第一次执行的时候一定要格式化文件系统,不要重复执行(hdfs namenode -format)</li>
  <li>启动集群 /sbin/start-dfs.sh</li>
  <li>查看是否启动成功,输入命令 jps   –&gt; 显示应该有4个进程</li>
  <li>启动日志 /home/hadoop/app/hadoop-2.6.0-cdh5.15.1/logs/</li>
  <li>启动成功过后默认hdfs端口为 50070,可浏览器访问,若访问不到,可能是防火墙原因
    <ol>
      <li>查看防火墙是否打开 firewall -cmd –state</li>
      <li>若打开,可以将其关闭 sudo systemctl stop firewalld.service</li>
    </ol>
  </li>
  <li>start/stop-dfs.sh 与 hadoop-daemons.sh的关系
    <ol>
      <li>start/stop-dfs.sh 是后面那个命令的组合</li>
      <li>hadoop-daemons.sh start namenode</li>
      <li>hadoop-daemons.sh start datanode</li>
    </ol>
  </li>
</ul>

:ET