I"à$<h4 id="å®‰è£…">å®‰è£…</h4>
<h5 id="å®‰è£…docker">å®‰è£…docker</h5>

<h6 id="masternodeèŠ‚ç‚¹éƒ½éœ€è¦å®‰è£…">Masterã€NodeèŠ‚ç‚¹éƒ½éœ€è¦å®‰è£…</h6>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code># å¸è½½åŸæ¥çš„docker
sudo yum remove docker \
                  docker-client \
                  docker-client-latest \
                  docker-common \
                  docker-latest \
                  docker-latest-logrotate \
                  docker-logrotate \
                  docker-engine

# å®‰è£…ä¾èµ–
sudo yum update -y &amp;&amp; sudo yum install -y yum-utils \
  device-mapper-persistent-data \
  lvm2

# æ·»åŠ å®˜æ–¹yumåº“
sudo yum-config-manager \
    --add-repo \
    https://download.docker.com/linux/centos/docker-ce.repo

# å®‰è£…docker å®‰è£…æŒ‡å®šç‰ˆæœ¬çš„docker,éœ€è¦kubernetsæ”¯æŒçš„æ‰è¡Œï¼Œè¿™é‡Œå®‰è£…18.9.7

# sudo yum install docker-ce docker-ce-cli containerd.io
yum install -y docker-ce-18.09.7 docker-ce-cli-18.09.7 containerd.io

# æŸ¥çœ‹dockerç‰ˆæœ¬
docker --version

# å¼€æœºå¯åŠ¨
systemctl enable --now docker
</code></pre></div></div>

<h6 id="æˆ–è€…ä½¿ç”¨è„šæœ¬ä¸€ä»¶å®‰è£…">æˆ–è€…ä½¿ç”¨è„šæœ¬ä¸€ä»¶å®‰è£…</h6>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>curl -fsSL "https://get.docker.com/" | sh
systemctl enable --now docker
</code></pre></div></div>

<h6 id="ä¿®æ”¹docker-cgroupé©±åŠ¨ä¸k8sä¸€è‡´ä½¿ç”¨systemd">ä¿®æ”¹docker cgroupé©±åŠ¨ï¼Œä¸k8sä¸€è‡´ï¼Œä½¿ç”¨systemd</h6>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code># ä¿®æ”¹docker cgroupé©±åŠ¨ï¼šnative.cgroupdriver=systemd
cat &gt; /etc/docker/daemon.json &lt;&lt;EOF
{
  "exec-opts": ["native.cgroupdriver=systemd"],
  "log-driver": "json-file",
  "log-opts": {
    "max-size": "100m"
  },
  "storage-driver": "overlay2",
  "storage-opts": [
    "overlay2.override_kernel_check=true"
  ]

  # è¿™é‡Œå¯ä»¥åŠ å…¥ä¸‹è½½åŠ é€Ÿçš„æº
  # "registry-mirrors": ["https://xxxxx.mirror.aliyuncs.com"]
}
EOF

systemctl restart docker  # é‡å¯ä½¿é…ç½®ç”Ÿæ•ˆ
</code></pre></div></div>

<h5 id="å®‰è£…-kubelet-kubeadm-kubectl">å®‰è£… kubelet kubeadm kubectl</h5>

<p>masterã€nodeèŠ‚ç‚¹éƒ½éœ€è¦å®‰è£…kubelet kubeadm kubectlã€‚</p>

<p>å®‰è£…kubernetesçš„æ—¶å€™ï¼Œéœ€è¦å®‰è£…kubelet, kubeadmç­‰åŒ…ï¼Œä½†k8så®˜ç½‘ç»™çš„yumæºæ˜¯packages.cloud.google.comï¼Œå›½å†…è®¿é—®ä¸äº†ï¼Œæ­¤æ—¶æˆ‘ä»¬å¯ä»¥ä½¿ç”¨é˜¿é‡Œäº‘çš„yumä»“åº“é•œåƒ</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=http://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64
enabled=1
gpgcheck=0
repo_gpgcheck=0
gpgkey=http://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg
       http://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg
EOF

# å…³é—­SElinux
setenforce 0
sed -i 's/^SELINUX=enforcing$/SELINUX=permissive/' /etc/selinux/config

# å®‰è£…kubelet kubeadm kubectl
yum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes

systemctl enable --now kubelet  # å¼€æœºå¯åŠ¨kubelet

# centos7ç”¨æˆ·è¿˜éœ€è¦è®¾ç½®è·¯ç”±ï¼š
yum install -y bridge-utils.x86_64
modprobe  br_netfilter  # åŠ è½½br_netfilteræ¨¡å—ï¼Œä½¿ç”¨lsmodæŸ¥çœ‹å¼€å¯çš„æ¨¡å—
cat &lt;&lt;EOF &gt;  /etc/sysctl.d/k8s.conf
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
EOF
sysctl --system  # é‡æ–°åŠ è½½æ‰€æœ‰é…ç½®æ–‡ä»¶

systemctl disable --now firewalld  # å…³é—­é˜²ç«å¢™

# k8sè¦æ±‚å…³é—­swap  (qxl)
swapoff -a &amp;&amp; sysctl -w vm.swappiness=0  # å…³é—­swap
sed -ri '/^[^#]*swap/s@^@#@' /etc/fstab  # å–æ¶ˆå¼€æœºæŒ‚è½½swap
</code></pre></div></div>

<h5 id="åˆ›å»ºé›†ç¾¤å‡†å¤‡å·¥ä½œ">åˆ›å»ºé›†ç¾¤å‡†å¤‡å·¥ä½œ</h5>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code># Masterç«¯ï¼š
kubeadm config images pull # æ‹‰å–é›†ç¾¤æ‰€éœ€é•œåƒï¼Œè¿™ä¸ªéœ€è¦ç¿»å¢™

# --- ä¸èƒ½ç¿»å¢™å¯ä»¥å°è¯•ä»¥ä¸‹åŠæ³• ---
kubeadm config images list # åˆ—å‡ºæ‰€éœ€é•œåƒ æ ¹æ®è‡ªå·±éœ€è¦ä¸‹è½½

docker pull mirrorgooglecontainers/kube-apiserver-amd64:v1.16.1
docker pull mirrorgooglecontainers/kube-controller-manager-amd64:v1.16.1
docker pull mirrorgooglecontainers/kube-scheduler-amd64:v1.16.1
docker pull mirrorgooglecontainers/kube-proxy-amd64:v1.16.1
docker pull mirrorgooglecontainers/pause:3.1
docker pull mirrorgooglecontainers/etcd:3.3.15-0
docker pull coredns/coredns:1.6.2

# ä¸‹è½½å®Œæ¯•åæ‰“tag
docker tag mirrorgooglecontainers/kube-apiserver-amd64:v1.16.1 k8s.gcr.io/kube-apiserver:v1.16.1

docker tag mirrorgooglecontainers/kube-controller-manager-amd64:v1.16.1 k8s.gcr.io/kube-controller-manager:v1.16.1

docker tag mirrorgooglecontainers/kube-scheduler-amd64:v1.16.1 k8s.gcr.io/kube-scheduler:v1.16.1

docker tag mirrorgooglecontainers/kube-proxy-amd64:v1.16.1 k8s.gcr.io/kube-proxy:v1.16.1

docker tag mirrorgooglecontainers/pause:3.1 k8s.gcr.io/pause:3.1

docker tag mirrorgooglecontainers/etcd:3.3.15-0 k8s.gcr.io/etcd:3.3.15-0

docker tag coredns/coredns:1.6.2 k8s.gcr.io/coredns:1.6.2

# åˆ é™¤åŸæ¥çš„é•œåƒ

# Nodeç«¯ï¼š
# æ ¹æ®æ‰€éœ€é•œåƒåå­—å…ˆæ‹‰å–å›½å†…èµ„æº
docker pull mirrorgooglecontainers/kube-proxy-amd64:v1.16.1
docker pull mirrorgooglecontainers/pause:3.1


# ä¿®æ”¹é•œåƒtag
docker tag mirrorgooglecontainers/kube-proxy-amd64:v1.16.1 k8s.gcr.io/kube-proxy:v1.16.1

docker tag mirrorgooglecontainers/pause:3.1 k8s.gcr.io/pause:3.1

# åˆ é™¤åŸæ¥çš„é•œåƒ
</code></pre></div></div>

<h5 id="ä½¿ç”¨kubeadmåˆ›å»ºé›†ç¾¤">ä½¿ç”¨kubeadmåˆ›å»ºé›†ç¾¤</h5>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code># ç¬¬ä¸€æ¬¡åˆå§‹åŒ–è¿‡ç¨‹ä¸­/etc/kubernetes/admin.confè¯¥æ–‡ä»¶å­˜åœ¨ï¼Œæ˜¯ç©ºæ–‡ä»¶ï¼ˆæˆ‘è‡ªå·±æ‰‹åŠ¨åˆ›å»ºçš„ï¼‰ï¼Œä¼šæŠ¥é”™ï¼španic: runtime error: invalid memory address or nil pointer dereference
ls /etc/kubernetes/admin.conf &amp;&amp; mv /etc/kubernetes/admin.conf.bak # ç§»èµ°å¤‡ä»½

# åˆå§‹åŒ–Masterï¼ˆMasteréœ€è¦è‡³å°‘2æ ¸ï¼‰æ­¤å¤„ä¼šå„ç§æŠ¥é”™,å¼‚å¸¸...æˆåŠŸä¸å¦å°±åœ¨æ­¤
kubeadm init --apiserver-advertise-address 192.168.200.25 --pod-network-cidr 10.244.0.0/16 # --kubernetes-version 1.14.1
# --apiserver-advertise-address æŒ‡å®šä¸å…¶å®ƒèŠ‚ç‚¹é€šä¿¡çš„æ¥å£
# --pod-network-cidr æŒ‡å®špodç½‘ç»œå­ç½‘ï¼Œä½¿ç”¨fannelç½‘ç»œå¿…é¡»ä½¿ç”¨è¿™ä¸ªCIDR
</code></pre></div></div>

<h6 id="æ™®é€šç”¨æˆ·è®¾ç½®æƒé™">æ™®é€šç”¨æˆ·è®¾ç½®æƒé™</h6>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>mkdir -p $HOME/.kube
  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
  sudo chown $(id -u):$(id -g) $HOME/.kube/config
</code></pre></div></div>
<h6 id="åº”ç”¨flannelç½‘ç»œ">åº”ç”¨flannelç½‘ç»œ</h6>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code># https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/#tabs-pod-install-4
kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/2140ac876ef134e0ed5af15c65e414cf26827915/Documentation/kube-flannel.yml


</code></pre></div></div>

<h6 id="ä½¿ç”¨nodeåŠ å…¥é›†ç¾¤">ä½¿ç”¨nodeåŠ å…¥é›†ç¾¤</h6>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>kubeadm join 172.16.54.145:6443 --token ppj0ts.1x5lh80gcgj84qr1 \
    --discovery-token-ca-cert-hash sha256:14fbe55aa9cbae02fc558aa9e34da44f95840133309885b5b6f8a8895f924409
</code></pre></div></div>

<h6 id="æŸ¥çœ‹">æŸ¥çœ‹</h6>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code># masterï¼š
kubectl get pods --all-namespaces
# ---è¾“å‡ºä¿¡æ¯---
NAMESPACE     NAME                             READY   STATUS    RESTARTS   AGE
kube-system   coredns-fb8b8dccf-rn8kd          1/1     Running   0          170m
kube-system   coredns-fb8b8dccf-slwr4          1/1     Running   0          170m
kube-system   etcd-master                      1/1     Running   0          169m
kube-system   kube-apiserver-master            1/1     Running   0          169m
kube-system   kube-controller-manager-master   1/1     Running   0          169m
kube-system   kube-flannel-ds-amd64-l8c7c      1/1     Running   0          130m
kube-system   kube-flannel-ds-amd64-lcmxw      1/1     Running   1          117m
kube-system   kube-flannel-ds-amd64-pqnln      1/1     Running   1          72m
kube-system   kube-proxy-4kcqb                 1/1     Running   0          170m
kube-system   kube-proxy-jcqjd                 1/1     Running   0          72m
kube-system   kube-proxy-vm9sj                 1/1     Running   0          117m
kube-system   kube-scheduler-master            1/1     Running   0          169m
# ---è¾“å‡ºä¿¡æ¯---


kubectl get nodes
# ---è¾“å‡ºä¿¡æ¯---
NAME     STATUS   ROLES    AGE    VERSION
master   Ready    master   171m   v1.14.1
node1    Ready    &lt;none&gt;   118m   v1.14.1
node2    Ready    &lt;none&gt;   74m    v1.14.1
# ---è¾“å‡ºä¿¡æ¯---
</code></pre></div></div>

<h6 id="æŸ¥çœ‹æ—¥å¿—">æŸ¥çœ‹æ—¥å¿—</h6>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ournalctl -f  # å½“å‰è¾“å‡ºæ—¥å¿—
journalctl -f -u kubelet  # åªçœ‹å½“å‰çš„kubeletè¿›ç¨‹æ—¥å¿—
</code></pre></div></div>

<h6 id="dashboardå®‰è£…">DashBoardå®‰è£…</h6>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v2.0.0-beta4/aio/deploy/recommended.yaml

</code></pre></div></div>
:ET